{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a89928",
   "metadata": {},
   "source": [
    "# Transform dataset to LibKGE-ready files\n",
    "Generates the .del files in the format that LibKGE reads them.\n",
    "\n",
    "Required files for this Jupyter Notebook to work.\n",
    "1. Two mapping CSV files which contains information about all entities in Wikidata5M and all relatins for the entities in Wikidata5M. You can check the 02_csv_mapping_entities.csv and 02_csv_mapping_relations.csv file for the format or just use it directly.\n",
    "3. A folder containing a JSON file for each entity in Wikidata5M and all relations.\n",
    "\n",
    "## How does this Notebook work?\n",
    "The notebook is divided into five different sections. Sections 1, 2, 3 and 5 start with a cell where you need to set variables according to the dataset you want to create. Section 4 is a room for you to pre-process the data if you need to. If you don't need to change anything you can skip section 4.\n",
    "\n",
    "To create a dataset you have to go through the Notebook and run each cell. You need to set variables in the cells that start with #please set variables. And es mentioned before, section 4 is for you to pre-process your data the way you need it.\n",
    "E.g.: Transforming a date into a number to create a regression downstream task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7ce46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c33713d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables\n",
    "libkge_entity_ids = \"00_wikidata5m_entity_ids.del\"\n",
    "json_download_folder = '01_download_entities_relations'\n",
    "folder_of_triples = '07_datasets/airport_elevation_above_sea_level'\n",
    "downstreak_task_type = 'regression'  #regression or classification\n",
    "train_percentage = 0.8\n",
    "valid_percentage = 0.1\n",
    "test_percentage = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c943897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder_of_triples + '/all_triples.csv', delimiter=';', header=None)\n",
    "df = df.rename(columns={0: 'entity_id', 1: 'relation_id', 2: 'value'})\n",
    "df['value'] = df['value'].replace('\\[', '', regex=True).replace('\\]', '', regex=True).replace(\"'\", '', regex=True).replace(', ', ',', regex=True)\n",
    "relation_id = df['relation_id'].loc[0]\n",
    "df = df.set_index('entity_id')\n",
    "df = df.drop(['relation_id'], axis=1)\n",
    "\n",
    "if downstreak_task_type == 'classification':\n",
    "    df['value'] = df['value'].apply(lambda x: x.split(',')).to_frame()\n",
    "    df = df.explode('value')\n",
    "    df = pd.get_dummies(df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e72d5de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07_datasets/album_producer/06_notebook_triples_to_libkge.ipynb'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = folder_of_triples\n",
    "\n",
    "#mapping the wikidata IDs to the IDs for LibKGE in the entity_ids.del file\n",
    "df_mapping = pd.read_csv(libkge_entity_ids, sep='\\t', names=['libkge_id','entity_id']).set_index(\"entity_id\")\n",
    "df = df.merge(df_mapping, on='entity_id', how='left')\n",
    "df = df.set_index(\"libkge_id\")\n",
    "\n",
    "#creating the split files\n",
    "train_size = int(len(df) * train_percentage)\n",
    "valid_size = int(len(df) * valid_percentage)\n",
    "test_size = int(len(df) * test_percentage)\n",
    "\n",
    "df_train = df.iloc[:train_size]\n",
    "df_valid = df.iloc[train_size:train_size + valid_size]\n",
    "df_test = df.iloc[train_size + valid_size:]\n",
    "\n",
    "df_train.to_csv(path + \"/train.del\", sep=\"\\t\", index=True, header=False)\n",
    "df_valid.to_csv(path + \"/valid.del\", sep=\"\\t\", index=True, header=False)\n",
    "df_test.to_csv(path + \"/test.del\", sep=\"\\t\", index=True, header=False)\n",
    "\n",
    "#README FILE\n",
    "with open(os.path.join(path, \"README.md\"), \"a\") as file:\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"Split for LibKGE created with 06_notebook_triples_to_libkge.\\n\")\n",
    "    file.write(\"Variables in notebook:\\n\")\n",
    "    file.write(\"json_download_folder:                  {}\\n\".format(json_download_folder))    \n",
    "    file.write(\"folder_of_triples:                     {}\\n\".format(folder_of_triples))\n",
    "    file.write(\"downstreak_task_type:                  {}\\n\".format(downstreak_task_type))\n",
    "    file.write(\"train_percentage:                      {}\\n\".format(train_percentage))\n",
    "    file.write(\"valid_percentage:                      {}\\n\".format(valid_percentage))\n",
    "    file.write(\"test_percentage:                       {}\\n\".format(test_percentage))\n",
    "shutil.copyfile('06_notebook_triples_to_libkge.ipynb', path + '/06_notebook_triples_to_libkge.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed941bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
